{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413aad2c",
   "metadata": {},
   "source": [
    "#### Visualize the existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b2f013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gezachar/github/Search-R1/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/gezachar/github/Search-R1/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 79168 examples [00:00, 3426281.64 examples/s]\n",
      "Generating dev split: 8757 examples [00:00, 2303802.30 examples/s]\n",
      "Generating test split: 3610 examples [00:00, 979964.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets    \n",
    "\n",
    "dataset = datasets.load_dataset('RUC-NLPIR/FlashRAG_datasets', 'nq')\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb1f1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample examples from the training dataset:\n",
      "{'id': 'train_0', 'question': 'total number of death row inmates in the us', 'golden_answers': ['2,718']}\n",
      "{'id': 'train_1', 'question': 'big little lies season 2 how many episodes', 'golden_answers': ['seven']}\n",
      "{'id': 'train_2', 'question': 'who sang waiting for a girl like you', 'golden_answers': ['Foreigner']}\n",
      "{'id': 'train_3', 'question': 'where do you cross the arctic circle in norway', 'golden_answers': ['Saltfjellet']}\n",
      "{'id': 'train_4', 'question': 'who is the main character in green eggs and ham', 'golden_answers': ['Sam-I-am']}\n",
      "\n",
      "Sample examples from the test dataset:\n",
      "{'id': 'test_0', 'question': 'who got the first nobel prize in physics', 'golden_answers': ['Wilhelm Conrad Röntgen']}\n",
      "{'id': 'test_1', 'question': 'when is the next deadpool movie being released', 'golden_answers': ['May 18, 2018']}\n",
      "{'id': 'test_2', 'question': 'which mode is used for short wave broadcast service', 'golden_answers': ['Olivia', 'MFSK']}\n",
      "{'id': 'test_3', 'question': 'the south west wind blows across nigeria between', 'golden_answers': ['till September']}\n",
      "{'id': 'test_4', 'question': 'what does hp mean in war and order', 'golden_answers': ['hit points or health points']}\n"
     ]
    }
   ],
   "source": [
    "# Print sample examples from each dataset\n",
    "print(\"Sample examples from the training dataset:\")\n",
    "for i, example in enumerate(train_dataset):\n",
    "    if i >= 5:  # Print first 5 examples\n",
    "        break\n",
    "    print(example)\n",
    "\n",
    "print(\"\\nSample examples from the test dataset:\")\n",
    "for i, example in enumerate(test_dataset):\n",
    "    if i >= 5:  # Print first 5 examples\n",
    "        break\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f5d32",
   "metadata": {},
   "source": [
    "## Load our CPQ D2 dataset\n",
    "https://orahub.oci.oraclecorp.com/cx-cnap/agent-dbt-mlops/-/blob/dbt/seeds/all_combinations.json?ref_type=heads has the input output pairs of the user request and the product configuration output, with labels for `correct` and `incorrect`.\n",
    "\n",
    "We only need the `correct` pairs for training in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a5f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 378/378 [00:00<00:00, 69139.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "### Edit this path to point to the data source\n",
    "with open(\"../datasets/all_combinations.json\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# Extract the actual data list\n",
    "data = raw[\"pairs\"]\n",
    "\n",
    "# Create a Dataset object\n",
    "dataset = Dataset.from_list(data)\n",
    "print(len(dataset))\n",
    "\n",
    "# Get only correct labels\n",
    "correct_dataset = dataset.filter(lambda x: x[\"label\"] == \"correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f164fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "{'input': 'What is the total cost of a High-Performance Compute Cluster with 2 GPU units, 256GB DDR4 memory and 1TB SSD storage?', 'output': {'compute_units': ['CPU', 'GPU'], 'features': [], 'memory': '128GB DDR4', 'package': 'Standard', 'product': 'High-Performance Compute Cluster', 'storage': '2TB NVMe'}, 'label': 'incorrect'}\n",
      "['Secure Boot']\n"
     ]
    }
   ],
   "source": [
    "print(len(correct_dataset))\n",
    "print(dataset[1])\n",
    "print(dataset[5]['output']['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f5e399",
   "metadata": {},
   "source": [
    "#### Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7473cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Shuffle and split into train/test\n",
    "import random\n",
    "\n",
    "TEST_SPLIT_RATIO = 0.2\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "indices = list(range(len(dataset)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "\n",
    "split_index = int(len(indices) * (1 - TEST_SPLIT_RATIO))\n",
    "train_indices = indices[:split_index]\n",
    "test_indices = indices[split_index:]\n",
    "\n",
    "train_dataset = dataset.select(train_indices)\n",
    "test_dataset = dataset.select(test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb73527b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c338046",
   "metadata": {},
   "source": [
    "### Reformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20780778",
   "metadata": {},
   "source": [
    "#### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "758a8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prefix(dp, template_type):\n",
    "    question = dp['input']\n",
    "\n",
    "    # NOTE: also need to change reward_score/countdown.py\n",
    "    if template_type == 'base':\n",
    "        \"\"\"This works for any base model\"\"\"\n",
    "        prefix = f\"\"\"Answer the given question. \\\n",
    "You must conduct reasoning inside <think> and </think> first every time you get new information. \\\n",
    "After reasoning, if you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>. \\\n",
    "You can search as many times as your want. \\\n",
    "If you find no further external knowledge needed, you can directly provide the answer inside <answer> and </answer>, without detailed illustrations. For example, <answer> Beijing </answer>. Question: {question}\\n\"\"\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fccbafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a row to each data item that represents a unique id\n",
    "data_source = 'cpq'\n",
    "\n",
    "def make_map_fn(split):\n",
    "\n",
    "    def process_fn(example, idx):\n",
    "        # print(example)\n",
    "        example['input'] = example['input'].strip()\n",
    "        # if example['input'][-1] != '?':\n",
    "        #     example['input'] += '?'\n",
    "        question = make_prefix(example, template_type=\"base\")\n",
    "        solution = {\n",
    "            \"target\": example['output'],\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            \"data_source\": data_source,\n",
    "            \"prompt\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }],\n",
    "            \"ability\": \"fact-reasoning\",\n",
    "            \"reward_model\": {\n",
    "                \"style\": \"rule\",\n",
    "                \"ground_truth\": solution\n",
    "            },\n",
    "            \"extra_info\": {\n",
    "                'split': split,\n",
    "                'index': idx,\n",
    "            }\n",
    "        }\n",
    "        return data\n",
    "\n",
    "    return process_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29b386b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 302/302 [00:00<00:00, 8649.05 examples/s]\n",
      "Map: 100%|██████████| 76/76 [00:00<00:00, 6724.62 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 620.37ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 932.69ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82856"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(function=make_map_fn('train'), with_indices=True)\n",
    "test_dataset = test_dataset.map(function=make_map_fn('test'), with_indices=True)\n",
    "\n",
    "local_dir = \"../data/cpq_search\"\n",
    "\n",
    "train_dataset.to_parquet(os.path.join(local_dir, 'train.parquet'))\n",
    "test_dataset.to_parquet(os.path.join(local_dir, 'test.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d6f34",
   "metadata": {},
   "source": [
    "## Knowledge Corpus\n",
    "\n",
    "Source: https://orahub.oci.oraclecorp.com/cx-cnap/agent-dbt-mlops/-/blob/dbt/seeds/compute_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c557874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../datasets/compute_config.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "output = []\n",
    "id_counter = 0\n",
    "\n",
    "for product in data[\"compute_resource_configurations\"]:\n",
    "    base_price = product[\"base_price\"]\n",
    "    product_name = product[\"product\"]\n",
    "\n",
    "    for package in product[\"packages\"]:\n",
    "        title = f\"{product_name} - {package['name']}\"\n",
    "        lines = [\n",
    "            f\"Base Price: ${base_price}\",\n",
    "            f\"Package Modifier: ${package['price_modifier']}\"\n",
    "        ]\n",
    "\n",
    "        # Compute units\n",
    "        compute_texts = []\n",
    "        for unit in package.get(\"compute_units\", []):\n",
    "            unit_type = unit[\"type\"]\n",
    "            options = \", \".join([f\"{opt['model']} (${opt['price_modifier']})\" for opt in unit[\"options\"]])\n",
    "            compute_texts.append(f\"- {unit_type}: {options}\")\n",
    "        if compute_texts:\n",
    "            lines.append(\"Compute Units:\\n\" + \"\\n\".join(compute_texts))\n",
    "\n",
    "        # Memory\n",
    "        if \"memory_options\" in package:\n",
    "            memory = \", \".join([f\"{m['size']} (${m['price_modifier']})\" for m in package[\"memory_options\"]])\n",
    "            lines.append(f\"Memory Options: {memory}\")\n",
    "\n",
    "        # Storage\n",
    "        if \"storage_options\" in package:\n",
    "            storage = \", \".join([f\"{s['type']} (${s['price_modifier']})\" for s in package[\"storage_options\"]])\n",
    "            lines.append(f\"Storage Options: {storage}\")\n",
    "\n",
    "        # Features\n",
    "        if \"features\" in package:\n",
    "            features = \", \".join([f\"{f['feature']} (${f['price_modifier']})\" for f in package[\"features\"]])\n",
    "            lines.append(f\"Features: {features}\")\n",
    "\n",
    "        text = \"\\n\".join(lines)\n",
    "        output.append({\n",
    "            \"id\": str(id_counter),\n",
    "            \"contents\": f\"{title}\\n{text}\"\n",
    "        })\n",
    "        id_counter += 1\n",
    "\n",
    "# Write to JSONL\n",
    "with open(\"../data/cpq_knowledge_corpus.jsonl\", \"w\") as f:\n",
    "    for item in output:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Search-R1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
